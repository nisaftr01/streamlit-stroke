{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9aba645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annisa\\AppData\\Local\\Temp\\ipykernel_29164\\2279774981.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['bmi'].fillna(df['bmi'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping untuk gender: {'Female': np.int64(0), 'Male': np.int64(1), 'Other': np.int64(2)}\n",
      "Mapping untuk ever_married: {'No': np.int64(0), 'Yes': np.int64(1)}\n",
      "Mapping untuk work_type: {'Govt_job': np.int64(0), 'Never_worked': np.int64(1), 'Private': np.int64(2), 'Self-employed': np.int64(3), 'children': np.int64(4)}\n",
      "Mapping untuk Residence_type: {'Rural': np.int64(0), 'Urban': np.int64(1)}\n",
      "Mapping untuk smoking_status: {'Unknown': np.int64(0), 'formerly smoked': np.int64(1), 'never smoked': np.int64(2), 'smokes': np.int64(3)}\n",
      "Sedang melatih model... (Mungkin agak lama)\n",
      "Akurasi Training: 0.9522994129158513\n",
      "Akurasi Testing : 0.9510763209393346\n",
      "Berhasil! File 'stroke_stacking_model.sav' dan 'scaler_stroke.sav' sudah disimpan.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import Algoritma Stacking\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. LOAD DATASET\n",
    "# Pastikan nama file sesuai dengan yang kamu upload\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "# 2. DATA CLEANING (MEMBERSIHKAN DATA)\n",
    "# a. Hapus kolom ID karena tidak berguna untuk prediksi\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "# b. Perbaiki kolom BMI yang ada tulisan \"N/A\"\n",
    "# Ubah ke angka dulu (yang N/A jadi NaN/Kosong)\n",
    "df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce')\n",
    "# Isi yang kosong dengan rata-rata BMI\n",
    "df['bmi'].fillna(df['bmi'].mean(), inplace=True)\n",
    "\n",
    "# 3. ENCODING (UBAH TEKS JADI ANGKA)\n",
    "# Kita pakai LabelEncoder. Catat urutannya untuk dipakai di Streamlit nanti!\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Daftar kolom yang isinya Teks\n",
    "text_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "for col in text_columns:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    # Print ini agar kita tahu urutan angkanya untuk Streamlit\n",
    "    print(f\"Mapping untuk {col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# 4. MEMISAHKAN FITUR DAN LABEL\n",
    "X = df.drop(columns='stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "# 5. SCALING (STANDARDISASI)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_standard = scaler.transform(X)\n",
    "\n",
    "# 6. SPLIT DATA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standard, y, test_size=0.2, stratify=y, random_state=2)\n",
    "\n",
    "# 7. MEMBANGUN MODEL STACKING\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('svm', SVC(kernel='linear', probability=True)) \n",
    "]\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, \n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "# 8. TRAINING\n",
    "print(\"Sedang melatih model... (Mungkin agak lama)\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 9. CEK AKURASI\n",
    "train_acc = accuracy_score(clf.predict(X_train), y_train)\n",
    "test_acc = accuracy_score(clf.predict(X_test), y_test)\n",
    "print(f\"Akurasi Training: {train_acc}\")\n",
    "print(f\"Akurasi Testing : {test_acc}\")\n",
    "\n",
    "# 10. SIMPAN MODEL & SCALER\n",
    "pickle.dump(clf, open('stroke_stacking_model.sav', 'wb'))\n",
    "pickle.dump(scaler, open('scaler_stroke.sav', 'wb'))\n",
    "\n",
    "print(\"Berhasil! File 'stroke_stacking_model.sav' dan 'scaler_stroke.sav' sudah disimpan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
